# ğŸ§ª EasyML Pipeline Testing Guide

This guide provides comprehensive testing strategies for your complete EasyML MLOps pipeline. Test everything from individual components to full end-to-end workflows.

## ğŸš€ Quick Start Testing

### 1. **Basic Health Check** (30 seconds)
```bash
# Test if server is running
curl http://localhost:8000/health

# Test API documentation
curl http://localhost:8000/docs
```

### 2. **Quick Pipeline Test** (2-3 minutes)
```bash
# Run essential tests only
./test_pipeline.sh --quick
```

### 3. **Complete Pipeline Test** (5-10 minutes)
```bash
# Run full end-to-end test
python3 test_complete_pipeline.py
```

---

## ğŸ“‹ Testing Components

### ğŸ”„ **Complete Pipeline Testing**

Test the entire ML pipeline from data upload to deployment:

```bash
# Full automated pipeline test
python3 test_complete_pipeline.py

# What it tests:
# âœ… Server health
# âœ… User registration & authentication  
# âœ… Project creation
# âœ… Data upload (synthetic dataset)
# âœ… Model training (Random Forest)
# âœ… Model versioning (DVC integration)
# âœ… Deployment preparation
# âœ… Prediction testing
# âœ… Database integration
```

**Expected Output:**
```
ğŸš€ EasyML Complete Pipeline Test
============================================

[12:34:56] HEALTH: Testing server health...
[12:34:56] HEALTH: âœ… Server is running
[12:34:57] AUTH: Registering test user...
[12:34:58] AUTH: âœ… User registered successfully
[12:34:59] AUTH: âœ… User logged in successfully
...
ğŸ“Š PIPELINE TEST SUMMARY
Tests Passed: 8/9 (88.9%)
ğŸ‰ PIPELINE TEST SUCCESSFUL!
```

---

### ğŸ—ï¸ **Infrastructure Testing**

Test all infrastructure components:

```bash
# Complete infrastructure test
./test_pipeline.sh --full

# Quick infrastructure test  
./test_pipeline.sh --quick

# API endpoints only
./test_pipeline.sh --api-only
```

**Components Tested:**
- âœ… **Database Connections** (PostgreSQL + MongoDB)
- âœ… **DVC Setup** (Data Version Control)
- âœ… **Docker Configuration** 
- âœ… **API Endpoints**
- âœ… **GitHub Workflows**
- âœ… **Performance Metrics**
- âœ… **Security Basics**

---

### âš¡ **Performance & Load Testing**

Test system performance under load:

```bash
# Run load test with concurrent users
python3 test_load_performance.py

# Configuration (edit script to modify):
NUM_CONCURRENT_USERS = 10
NUM_REQUESTS_PER_USER = 5
```

**Load Test Scenarios:**
- ğŸ‘¥ **Concurrent Users**: Simulates multiple users
- ğŸ”„ **Complete Journeys**: Auth â†’ Project â†’ Training
- ğŸ“Š **Performance Metrics**: Response times, throughput
- ğŸ¯ **Success Rates**: Error rates and reliability

**Expected Output:**
```
âš¡ EasyML Load Testing Suite
========================================
ğŸ‘¤ Starting user 0 journey...
ğŸ‘¤ Starting user 1 journey...
...
ğŸ“Š LOAD TEST ANALYSIS
==================================================
Total Requests: 200
Successful Requests: 195
Success Rate: 97.50%

Response Time Statistics:
  Mean: 0.245s
  95th Percentile: 0.890s
  Max: 1.234s

ğŸ¯ Performance Assessment:
âœ… EXCELLENT - System performs well under load
```

---

### âš™ï¸ **GitHub Actions Testing**

Validate GitHub workflows locally:

```bash
# Validate workflow syntax and configuration
python3 test_github_workflows.py

# Check specific workflow
act --workflow ci-cd-pipeline.yml --dry-run  # (requires 'act' tool)
```

**Workflow Validation:**
- âœ… **YAML Syntax** validation
- âœ… **Required Secrets** identification
- âœ… **Environment Variables** check
- âœ… **Docker Integration** verification
- âœ… **Azure Integration** validation

---

## ğŸ§ª Manual Testing Scenarios

### **Scenario 1: Data Scientist Workflow**
1. Register new user
2. Create classification project
3. Upload CSV dataset
4. Train multiple models
5. Compare model performance
6. Deploy best model

### **Scenario 2: MLOps Engineer Workflow**
1. Monitor model performance
2. Check DVC model versions
3. Test deployment endpoints
4. Validate monitoring dashboards
5. Test rollback procedures

### **Scenario 3: Production Readiness**
1. Load test with realistic data
2. Security vulnerability scan
3. Database performance test
4. Container deployment test
5. Azure integration test

---

## ğŸ“Š Testing Environments

### **Development Environment**
```bash
# Local testing with Docker Compose
docker-compose up -d
./test_pipeline.sh --full
```

### **Staging Environment**
```bash
# Test against staging deployment
BASE_URL="https://easyml-staging.azurecontainerinstances.io" \
python3 test_complete_pipeline.py
```

### **Production Readiness**
```bash
# Full production readiness check
./test_pipeline.sh --full
python3 test_load_performance.py
python3 test_github_workflows.py
```

---

## ğŸ”§ Troubleshooting Common Issues

### **Server Not Starting**
```bash
# Check logs
docker-compose logs app

# Check ports
netstat -tulpn | grep 8000

# Restart services
docker-compose down && docker-compose up -d
```

### **Database Connection Issues**
```bash
# Test database directly
python3 check_db_records.py

# Check environment variables
cat .env | grep -E "(POSTGRES|MONGO)"

# Test MongoDB SSL
python3 scripts/test_mongodb_ssl.py
```

### **DVC Issues**
```bash
# Check DVC status
dvc status

# Check DVC remote
dvc remote list

# Test DVC storage
ls -la dvc_storage/models/
```

### **Authentication Failures**
```bash
# Check JWT configuration
curl -X POST http://localhost:8000/api/v1/auth/register \
  -H "Content-Type: application/json" \
  -d '{"username":"test","email":"test@test.com","password":"testpass123"}'
```

---

## ğŸ“ˆ Performance Benchmarks

### **Expected Performance**
- âš¡ **Health Check**: < 100ms
- ğŸ‘¤ **Authentication**: < 500ms  
- ğŸ“Š **Model Training**: < 30s (small dataset)
- ğŸš€ **Prediction**: < 200ms
- ğŸ“‚ **File Upload**: < 2s (10MB file)

### **Load Test Targets**
- ğŸ¯ **Success Rate**: > 95%
- â±ï¸ **Response Time**: < 2s (95th percentile)
- ğŸ”„ **Throughput**: > 10 requests/second
- ğŸ‘¥ **Concurrent Users**: 50+ users

---

## ğŸš¨ Monitoring & Alerts

### **Health Monitoring**
```bash
# Continuous health monitoring
while true; do
  curl -f http://localhost:8000/health || echo "âš ï¸ Service down!"
  sleep 30
done
```

### **Performance Monitoring**
```bash
# Log response times
curl -w "Response time: %{time_total}s\n" http://localhost:8000/health
```

---

## ğŸ¯ CI/CD Integration

### **Pre-commit Testing**
```bash
# Add to .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: pipeline-test
        name: Pipeline Test
        entry: ./test_pipeline.sh --quick
        language: system
```

### **GitHub Actions Integration**
```yaml
# .github/workflows/test.yml
- name: Run Pipeline Tests
  run: |
    ./test_pipeline.sh --full
    python3 test_complete_pipeline.py
```

---

## ğŸ“ Test Reports

All testing scripts generate detailed reports:

- ğŸ“Š **Performance Metrics**: Response times, throughput
- âœ… **Success Rates**: Pass/fail statistics  
- ğŸ› **Error Analysis**: Detailed error breakdown
- ğŸ“ˆ **Trends**: Performance over time
- ğŸ¯ **Recommendations**: Optimization suggestions

---

## ğŸš€ Next Steps

1. **Automated Testing**: Set up CI/CD pipeline testing
2. **Monitoring**: Implement production monitoring
3. **Scaling**: Test horizontal scaling capabilities
4. **Security**: Run security penetration testing
5. **Documentation**: Update API documentation

---

## â“ Support & Resources

- ğŸ“š **API Documentation**: `http://localhost:8000/docs`
- ğŸ› **Issue Tracking**: GitHub Issues
- ğŸ“– **User Guide**: `README.md`
- ğŸ—ï¸ **Architecture**: `ARCHITECTURE.md`

---

**Testing is crucial for MLOps success! ğŸ¯**

Regular testing ensures your pipeline remains reliable, performant, and ready for production workloads.
